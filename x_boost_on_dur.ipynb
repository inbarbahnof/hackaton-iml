{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn.model_selection as sk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "import logging\n",
    "from typing import NoReturn\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as sk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import evaluation_scripts.eval_passengers_up as eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BUS_CSV_PATH = \"data/train_bus_schedule.csv\"\n",
    "X_PASSENGER = \"data/X_passengers_up.csv\"\n",
    "X_TRIP = \"data/X_trip_duration.csv\"\n",
    "ENCODER = \"windows-1255\"\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bus = pd.read_csv(TRAIN_BUS_CSV_PATH, encoding=ENCODER)\n",
    "x_passenger = pd.read_csv(X_PASSENGER, encoding=ENCODER)\n",
    "x_trip_duration = pd.read_csv(X_TRIP, encoding=ENCODER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bus = pd.read_csv(TRAIN_BUS_CSV_PATH, encoding=ENCODER)\n",
    "x_trip = pd.read_csv(X_TRIP, encoding=ENCODER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_for_baseline = train_bus[\"trip_id_unique\"].drop_duplicates().sample(frac=0.10,\n",
    "                                                                        random_state=RANDOM_STATE)\n",
    "dur_remaining = train_bus[~train_bus[\"trip_id_unique\"].isin(lines_for_baseline)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_for_xboost = dur_remaining[\"trip_id_unique\"].drop_duplicates().sample(frac=0.28,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_remaining = train_bus[~train_bus[\"trip_id_unique\"].isin(lines_for_xboost)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __creating_labels(dur_baseline):\n",
    "    min_max_time = dur_baseline.groupby(\"trip_id_unique\")[\"arrival_time\"].agg(\n",
    "        {\"min\", \"max\"}).reset_index()\n",
    "    min_max_time[\"max\"] = pd.to_datetime(min_max_time[\"max\"])\n",
    "    min_max_time[\"min\"] = pd.to_datetime(min_max_time[\"min\"])\n",
    "    min_max_time[\"delta\"] = (min_max_time[\"max\"] - min_max_time[\"min\"]) / pd.Timedelta(1, \"m\")\n",
    "    min_max_time[\"delta\"] = round(min_max_time[\"delta\"], 2)\n",
    "    return min_max_time[[\"trip_id_unique\", \"delta\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/24/vfbkhj7j0t142rz214mskjkr0000gn/T/ipykernel_74156/212821949.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  min_max_time[\"max\"] = pd.to_datetime(min_max_time[\"max\"])\n",
      "/var/folders/24/vfbkhj7j0t142rz214mskjkr0000gn/T/ipykernel_74156/212821949.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  min_max_time[\"min\"] = pd.to_datetime(min_max_time[\"min\"])\n"
     ]
    }
   ],
   "source": [
    "dur_labels = __creating_labels(dur_remaining)\n",
    "\n",
    "# # 2. preprocess the training set\n",
    "# logging.info(\"preprocessing train...\")\n",
    "# X_train, X_test, y_train, y_test = preprocessing_baseline(dur_baseline, dur_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/24/vfbkhj7j0t142rz214mskjkr0000gn/T/ipykernel_74156/2488329175.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  f_start_time['start_time'] = pd.to_datetime(f_start_time['start_time']).dt.hour\n"
     ]
    }
   ],
   "source": [
    "f_station_cnt = dur_remaining.groupby(\"trip_id_unique\")[\"trip_id_unique_station\"].nunique().to_frame(\n",
    "    \"station_cnt\")\n",
    "f_total_passenger = dur_remaining.groupby(\"trip_id_unique\")[\"passengers_up\"].sum().to_frame(\n",
    "    \"total_passenger\")\n",
    "f_mean_passenger = dur_remaining.groupby(\"trip_id_unique\")[\"passengers_up\"].mean().to_frame(\n",
    "    \"mean_passenger\")\n",
    "f_mean_passenger_c = dur_remaining.groupby(\"trip_id_unique\")[\"passengers_continue\"].mean().to_frame(\n",
    "    \"mean_passenger_c\")\n",
    "f_start_time = dur_remaining.groupby(\"trip_id_unique\")[\"arrival_time\"].min().to_frame(\"start_time\")\n",
    "f_start_time['start_time'] = pd.to_datetime(f_start_time['start_time']).dt.hour\n",
    "features = pd.concat(\n",
    "    [f_station_cnt, f_total_passenger, f_mean_passenger, f_mean_passenger_c, f_start_time],\n",
    "    axis=1)\n",
    "features = features.merge(dur_remaining[[\"trip_id_unique\", \"cluster\", \"direction\", \"mekadem_nipuach_luz\"]],on=\"trip_id_unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "features['cluster'] = label_encoder.fit_transform(features['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_weight = ['אצ\"ל',\n",
    " 'ביאליק',\n",
    " 'ההגנה',\n",
    " 'חזון',\n",
    " 'לוינסקי',\n",
    " 'סוקולוב',\n",
    " 'עקיבא',\n",
    " 'קניון',\n",
    " 'רבי',\n",
    " 'רכבת',\n",
    " 'אצ\"ל',\n",
    " 'ביאליק',\n",
    " 'בלפור',\n",
    " 'גשר',\n",
    " 'ההגנה',\n",
    " 'המלך',\n",
    " \"ז'בוטינסקי\",\n",
    " 'חזון',\n",
    " 'יוספטל',\n",
    " 'כצנלסון',\n",
    " 'לוינסקי',\n",
    " 'סוקולוב',\n",
    " 'עקיבא',\n",
    " 'קניון',\n",
    " 'רבי',\n",
    " 'רוטשילד']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_concat = dur_remaining.groupby(\"trip_id_unique\")[\"station_name\"].agg(lambda x: ', '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(words_weight, start=1):\n",
    "    station_concat[f'x_{i}'] = station_concat['station_name'].str.contains(word, regex=False).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del station_concat['station_name']\n",
    "features = features.merge(station_concat,on = \"trip_id_unique\")\n",
    "features = features.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m597.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/24/vfbkhj7j0t142rz214mskjkr0000gn/T/ipykernel_74156/2280330949.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  line_lengths_approx = dur_remaining.groupby('trip_id_unique').apply(calculate_approx_line_length).reset_index(name='line_length_approx')\n"
     ]
    }
   ],
   "source": [
    "def calculate_approx_line_length(group):\n",
    "    coords = list(zip(group['latitude'], group['longitude']))\n",
    "    total_length = 0.0\n",
    "    for i in range(len(coords) - 1):\n",
    "        total_length += geodesic(coords[i], coords[i + 1]).km\n",
    "    return total_length\n",
    "\n",
    "# Group by 'line_id' and calculate approximate line length\n",
    "line_lengths_approx = dur_remaining.groupby('trip_id_unique').apply(calculate_approx_line_length).reset_index(name='line_length_approx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.merge(line_lengths_approx,on = \"trip_id_unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id_unique</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110005c</td>\n",
       "      <td>97.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110007c</td>\n",
       "      <td>76.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110008c</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110009c</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110014c</td>\n",
       "      <td>113.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4328</th>\n",
       "      <td>421861a</td>\n",
       "      <td>94.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4329</th>\n",
       "      <td>421880a</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330</th>\n",
       "      <td>421882a</td>\n",
       "      <td>103.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4331</th>\n",
       "      <td>421931a</td>\n",
       "      <td>83.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>421998a</td>\n",
       "      <td>94.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4333 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     trip_id_unique   delta\n",
       "0           110005c   97.00\n",
       "1           110007c   76.00\n",
       "2           110008c   80.00\n",
       "3           110009c   82.00\n",
       "4           110014c  113.00\n",
       "...             ...     ...\n",
       "4328        421861a   94.22\n",
       "4329        421880a   72.00\n",
       "4330        421882a  103.00\n",
       "4331        421931a   83.00\n",
       "4332        421998a   94.00\n",
       "\n",
       "[4333 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dur_labels['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sk.train_test_split(features.drop(columns = [\"trip_id_unique\"]), dur_labels.drop(columns = [\"trip_id_unique\"]), train_size=0.75,\n",
    "                                                        random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xg_boost(X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series,\n",
    "             y_test: pd.Series):\n",
    "    results = []\n",
    "\n",
    "    # Define parameter grids to iterate over\n",
    "    parameters = [\n",
    "        {'max_depth': 3, 'learning_rate': 0.1, 'n_estimators': 100},\n",
    "        {'max_depth': 5, 'learning_rate': 0.1, 'n_estimators': 100},\n",
    "        {'max_depth': 5, 'learning_rate': 0.05, 'n_estimators': 100},\n",
    "        {'max_depth': 5, 'learning_rate': 0.1, 'n_estimators': 200},\n",
    "        {'max_depth': 7, 'learning_rate': 0.1, 'n_estimators': 100}\n",
    "    ]\n",
    "\n",
    "    for params in parameters:\n",
    "        # Create XGBoost model\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='rmse', **params)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate RMSE\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        results.append((params, rmse))\n",
    "\n",
    "    # Return results for further analysis or selection\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/iml.env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/iml.env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/iml.env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/iml.env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/iml.env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "result = xg_boost(X_train, X_test, y_train, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'max_depth': 3, 'learning_rate': 0.1, 'n_estimators': 100},\n",
       "  70.30254649230075),\n",
       " ({'max_depth': 5, 'learning_rate': 0.1, 'n_estimators': 100},\n",
       "  79.17302176967863),\n",
       " ({'max_depth': 5, 'learning_rate': 0.05, 'n_estimators': 100},\n",
       "  80.67238379498458),\n",
       " ({'max_depth': 5, 'learning_rate': 0.1, 'n_estimators': 200},\n",
       "  79.86132873106735),\n",
       " ({'max_depth': 7, 'learning_rate': 0.1, 'n_estimators': 100},\n",
       "  81.16479731329005)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
